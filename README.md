# Hong Kong Stock Pattern Recognition System

A comprehensive system for analyzing Hong Kong stock patterns using machine learning, technical indicators, and interactive analysis tools.

## ğŸ¯ Project Overview

This system provides an end-to-end pipeline for Hong Kong stock pattern recognition:

- **Data Collection**: Intelligent caching and bulk fetching for HK stocks
- **Pattern Recognition**: ML-powered detection of trading patterns
- **Feature Extraction**: 18+ technical indicators and pattern features
- **Interactive Analysis**: Real-time pattern matching with confidence scoring
- **Outcome Tracking**: Feedback loops for continuous model improvement

## âœ¨ Features

### Data Collection
- **ğŸ”„ Intelligent Caching**: Automatic local caching with incremental updates
- **ğŸ“Š Hong Kong Stock Focus**: Optimized for HK stock ticker formats (e.g., `0700.HK`)
- **ğŸ““ Jupyter Notebook Ready**: Designed for interactive data science workflows
- **ğŸš€ Progress Tracking**: Visual progress bars and detailed status updates
- **âš¡ Efficient Updates**: Only fetches missing data, not entire datasets
- **ğŸ›¡ï¸ Error Handling**: Robust error handling with retry logic

### Pattern Labeling
- **ğŸ·ï¸ Manual Pattern Labeling**: Interactive system for defining chart patterns
- **ğŸ“ JSON Persistence**: Structured storage with validation and error handling
- **ğŸ“Š Pattern Visualization**: Optional candlestick chart overlays (with mplfinance)
- **âœ… Comprehensive Validation**: Date range, ticker format, and data integrity checks
- **ğŸ”„ Pattern Management**: Add, load, and manage pattern collections

### Feature Extraction
- **ğŸ”¢ 18+ Numerical Features**: Comprehensive feature set across 4 categories
- **ğŸ“ˆ Technical Indicators**: 15+ indicators including SMA, RSI, MACD, Bollinger Bands
- **âš™ï¸ Configurable Windows**: Customizable analysis periods and parameters
- **ğŸ“„ ML-Ready Output**: CSV format optimized for machine learning workflows
- **ğŸ” Data Quality Checks**: Missing value detection and validation

### Signal Outcome Tagging
- **ğŸ“‹ Manual Feedback Collection**: Tag pattern match predictions with success/failure outcomes
- **ğŸ¯ Confidence Band Analysis**: Performance review by confidence score ranges
- **ğŸ”„ Feedback Loop Integration**: Enable continuous model improvement through real trading results
- **ğŸ’¾ Safe File Operations**: Automatic backups and versioned labeled outputs
- **ğŸ“Š Performance Tracking**: Statistical analysis of prediction accuracy over time

## ğŸš€ Quick Start

### Installation
```bash
pip install -r requirements.txt
```

### Interactive Demo (15 minutes)
```bash
jupyter notebook notebooks/core_workflow/06_interactive_analysis.ipynb
```

### Basic Workflow
```python
# 1. Data Collection
from stock_analyzer.data import fetch_hk_stocks
data = fetch_hk_stocks(['0700.HK', '0005.HK'], '2023-01-01', '2024-01-01')

# 2. Pattern Analysis
from stock_analyzer.analysis import InteractivePatternAnalyzer
analyzer = InteractivePatternAnalyzer()
results = analyzer.analyze_pattern_similarity('0700.HK', '2023-06-01', '2023-06-30', '0005.HK')

# 3. View Results
print(f"Found {len(results.matches_df)} pattern matches")
```

## ğŸ“š Documentation Structure

### Core Documentation
- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System architecture and component details
- **[PROJECT_REVIEW.md](docs/PROJECT_REVIEW.md)** - Current status and capabilities review
- **[PROGRESS.md](docs/PROGRESS.md)** - Development progress and milestones

### Technical Guides
- **[Workflow Guide](notebooks/README.md)** - Step-by-step usage workflows
- **[Bulk Data Fetching](Docs/bulk_fetching_guide.md)** - Large-scale data collection
- **[Setup Guide](docs/legacy/JUPYTEXT_AUTO_SYNC_GUIDE.md)** - Development environment setup

## ğŸ¯ Current Status

### âœ… Completed Components
- **Data Collection**: Enterprise-grade bulk fetching (100-1000+ stocks)
- **Pattern Recognition**: ML models with 70%+ accuracy
- **Feature Extraction**: 18+ technical indicators
- **Interactive Analysis**: Real-time confidence scoring
- **Outcome Tracking**: Feedback loop implementation

### ğŸ”„ Recent Updates
- **2025-01-26**: Interactive Pattern Analysis Enhancement - Confidence Score Issue Resolved
- **Performance**: 25% confidence score issue eliminated through enhanced training
- **Training Data**: 3x improvement in dataset size (3-4 â†’ 11-15 samples)
- **Model Selection**: Intelligent Random Forest fallback for small datasets

### ğŸ“Š Performance Metrics
- **Data Collection**: 88.8% file size reduction with git workflow
- **Pattern Detection**: 70%+ accuracy on labeled patterns
- **Processing Speed**: 15-180 minutes for 10-1000+ stocks
- **Storage Efficiency**: Intelligent caching with incremental updates

## ğŸ—ï¸ System Architecture

### Core Components
```
stock_analyzer/
â”œâ”€â”€ data/           # Data fetching and caching
â”œâ”€â”€ features/       # Feature extraction and indicators
â”œâ”€â”€ patterns/       # Pattern detection and labeling
â”œâ”€â”€ analysis/       # Interactive analysis and training
â””â”€â”€ visualization/  # Chart plotting and analysis
```

### Workflow Pipeline
```
Data Collection â†’ Feature Extraction â†’ Pattern Training â†’ Detection â†’ Analysis
```

## ğŸ“ˆ Getting Started Paths

### ğŸ”° Beginner (15-30 minutes)
1. **Interactive Demo**: `notebooks/core_workflow/06_interactive_analysis.ipynb`
2. **Quick Start**: `notebooks/examples/quick_start_demo.py`

### ğŸ“Š Data Analyst (1-2 hours)
1. **Data Collection**: `notebooks/core_workflow/01_data_collection.py`
2. **Feature Analysis**: `notebooks/core_workflow/03_feature_extraction.py`
3. **Visualization**: `notebooks/core_workflow/07_visualization.py`

### ğŸ¤– ML Engineer (2-4 hours)
1. **Model Training**: `notebooks/core_workflow/04_pattern_training.py`
2. **Pattern Detection**: `notebooks/core_workflow/05_pattern_detection.py`
3. **Signal Analysis**: `notebooks/core_workflow/08_signal_analysis.py`

## ğŸ› ï¸ Technical Stack

- **Data**: Yahoo Finance API, pandas, numpy
- **ML**: XGBoost, Random Forest, scikit-learn
- **Analysis**: Technical indicators, pattern recognition
- **Interface**: Jupyter notebooks, interactive widgets
- **Storage**: CSV/JSON local caching, git-friendly workflow

## ğŸ“ Support

- **Architecture Details**: See [ARCHITECTURE.md](docs/ARCHITECTURE.md)
- **Current Status**: See [PROJECT_REVIEW.md](docs/PROJECT_REVIEW.md)
- **Latest Updates**: See [PROGRESS.md](docs/PROGRESS.md)
- **Usage Examples**: See `notebooks/examples/`

---

**Last Updated**: January 2025 | **Version**: 2.0 | **Status**: Production Ready

### Legacy Usage Examples

#### Data Collection
```python
# Import the data fetching functions
from stock_analyzer.data import fetch_hk_stocks

# Fetch data for Hong Kong stocks
stock_data = fetch_hk_stocks(
    tickers=['0700.HK', '0005.HK'],  # Tencent, HSBC
    start_date='2023-01-01',
    end_date='2023-12-31',
    force_refresh=False  # Use cache if available
)

# Access individual stock data
tencent_data = stock_data['0700.HK']
print(tencent_data.head())
```

#### Pattern Labeling
```python
# Import pattern labeling functions
from src.pattern_labeler import PatternLabel, PatternLabeler

# Create a pattern label
pattern = PatternLabel(
    ticker="0700.HK",
    start_date="2023-02-10", 
    end_date="2023-03-03",
    label_type="positive",
    notes="Strong upward breakout pattern"
)

# Save to collection
labeler = PatternLabeler()
labeler.add_pattern(pattern)
labeler.save_patterns("labels/my_patterns.json")
```

#### Feature Extraction
```python
# Import feature extraction functions
from src.feature_extractor import extract_features_from_labels

# Extract features from all labeled patterns
features_df = extract_features_from_labels(
    labels_file="labels/labeled_patterns.json",
    output_file="features/labeled_features.csv"
)

print(f"Extracted {len(features_df)} feature sets with {features_df.shape[1]} columns")
```

#### Signal Outcome Tagging
```python
# Import signal outcome tagging functions
from src.signal_outcome_tagger import SignalOutcomeTagger, quick_tag_outcome

# Load latest match file and tag an outcome
tagger = SignalOutcomeTagger()
df = tagger.load_matches_file("signals/matches_20250622_212629.csv")

# Tag individual match outcome
tagger.tag_outcome(
    ticker="0005.HK",
    window_start_date="2024-06-14",
    outcome="success",
    feedback_notes="Breakout confirmed after 5 days"
)

# Save labeled results
tagger.save_labeled_matches("signals/matches_20250622_212629_labeled.csv")

# Review feedback by confidence bands
tagger.review_feedback()
```

## ğŸ“ Project Structure

```
StockAnalyze/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ fetcher.py               # Core data fetching logic
â”‚   â”œâ”€â”€ pattern_labeler.py       # Manual pattern labeling system
â”‚   â”œâ”€â”€ pattern_visualizer.py    # Optional chart visualization
â”‚   â”œâ”€â”€ signal_outcome_tagger.py # Signal outcome tagging for feedback
â”‚   â”œâ”€â”€ feature_extractor.py     # Feature extraction for ML
â”‚   â””â”€â”€ technical_indicators.py  # Technical analysis indicators
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_collection.ipynb      # Data collection notebook
â”‚   â”œâ”€â”€ pattern_labeling_demo.ipynb   # Pattern labeling demo
â”‚   â”œâ”€â”€ 04_feature_extraction.ipynb   # Feature extraction notebook
â”‚   â””â”€â”€ 08_signal_outcome_tagging.ipynb # Signal outcome tagging workflow
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data_fetcher.py          # Legacy data fetching tests
â”‚   â”œâ”€â”€ test_pattern_labeler.py       # Pattern labeling tests
â”‚   â”œâ”€â”€ test_feature_extractor.py     # Feature extraction tests
â”‚   â””â”€â”€ test_technical_indicators.py  # Technical indicators tests
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ feature_extraction_example.py # Feature extraction examples
â”œâ”€â”€ data/                             # Auto-created cache directory
â”œâ”€â”€ labels/                           # Pattern labels storage
â”œâ”€â”€ features/                         # Extracted features storage
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # This file
```

## ğŸ”§ API Reference

### Main Functions

#### `fetch_hk_stocks(tickers, start_date, end_date, force_refresh=False)`

Fetch and cache daily OHLCV data for Hong Kong stocks.

**Parameters:**
- `tickers` (List[str]): List of HK stock tickers (e.g., `['0700.HK', '0005.HK']`)
- `start_date` (str): Start date in 'YYYY-MM-DD' format
- `end_date` (str): End date in 'YYYY-MM-DD' format  
- `force_refresh` (bool): If True, ignore cache and fetch fresh data

**Returns:**
- `Dict[str, pd.DataFrame]`: Dictionary mapping ticker to DataFrame

#### `validate_tickers(tickers)`

Validate Hong Kong stock ticker formats.

**Parameters:**
- `tickers` (List[str]): List of ticker strings

**Returns:**
- `Tuple[List[str], List[str]]`: (valid_tickers, invalid_tickers)

#### `preview_cached_data(ticker)`

Display a preview of cached data for a specific ticker.

**Parameters:**
- `ticker` (str): Stock ticker to preview

#### `list_cached_tickers()`

Display all cached tickers with their date ranges and record counts.

## ğŸ“Š Data Format

Each stock returns a pandas DataFrame with the following columns:

| Column      | Type      | Description                        |
|-------------|-----------|-------------------------------------|
| Date        | datetime  | Trading day (DataFrame index)       |
| Open        | float     | Opening price                       |
| High        | float     | Daily high                          |
| Low         | float     | Daily low                           |
| Close       | float     | Closing price                       |
| Adj Close   | float     | Close adjusted for splits/dividends |
| Volume      | int       | Daily trading volume                |

## ğŸ—‚ï¸ Caching System

### How It Works

1. **First Run**: Downloads data from Yahoo Finance and saves to `data/{TICKER}.csv`
2. **Subsequent Runs**: Loads from cache and only fetches missing data
3. **Incremental Updates**: Automatically detects date gaps and fills them
4. **Force Refresh**: Use `force_refresh=True` to ignore cache

### Cache Management

```python
# Check what's in cache
list_cached_tickers()

# Preview specific ticker
preview_cached_data('0700.HK')

# Force refresh all data
fresh_data = fetch_hk_stocks(['0700.HK'], '2023-01-01', '2023-12-31', force_refresh=True)
```

### Cache Location

- **Directory**: `data/` (auto-created)
- **Format**: CSV files named `{TICKER}.csv` (e.g., `0700_HK.csv`)
- **Structure**: Date-indexed with all OHLCV columns

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test class
pytest tests/test_interactive_demo.py  # Modern test examples
```

### Test Coverage

- **Ticker Validation**: Format validation and error handling
- **Cache Management**: Save/load operations and data integrity
- **Date Range Logic**: Incremental update calculations
- **Yahoo Finance Integration**: API calls with mocking
- **Main Functions**: End-to-end workflow testing
- **Utility Functions**: Notebook helper functions

## ğŸ“ˆ Usage Examples

### Basic Data Collection

```python
# Collect data for major HK stocks
major_stocks = ['0700.HK', '0005.HK', '0941.HK', '0388.HK']
data = fetch_hk_stocks(major_stocks, '2023-01-01', '2023-12-31')

# Quick analysis
for ticker, df in data.items():
    print(f"{ticker}: {len(df)} records, latest price: ${df['Close'].iloc[-1]:.2f}")
```

### Incremental Updates

```python
# Initial data collection
data = fetch_hk_stocks(['0700.HK'], '2023-01-01', '2023-06-30')

# Later, extend the date range (only fetches new data)
extended_data = fetch_hk_stocks(['0700.HK'], '2023-01-01', '2023-12-31')
```

### Data Quality Checks

```python
# Check for missing data
for ticker, df in data.items():
    missing = df.isnull().sum().sum()
    if missing > 0:
        print(f"âš ï¸ {ticker} has {missing} missing values")
    else:
        print(f"âœ… {ticker} data is complete")
```

## âš™ï¸ Configuration

### Key Constants

```python
DATA_DIR = "data"                    # Cache directory
MAX_RETRIES = 2                      # API retry attempts
HK_TICKER_PATTERN = r"^\d{4}\.HK$"  # Valid ticker format
```

### Supported Ticker Format

- **Valid**: 4-digit number + ".HK" (e.g., `0700.HK`, `0005.HK`)
- **Invalid**: Other formats will be skipped with warnings

## ğŸ” Troubleshooting

### Common Issues

1. **Missing Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Network Issues**
   - The system retries failed requests automatically
   - Check internet connection for Yahoo Finance access

3. **Invalid Tickers**
   - Use 4-digit format with .HK suffix
   - Check ticker existence on Yahoo Finance

4. **Cache Issues**
   - Delete cache files in `data/` directory to reset
   - Use `force_refresh=True` to bypass cache

### Getting Help

```python
# Validate your tickers first
valid, invalid = validate_tickers(['0700.HK', 'INVALID'])
print(f"Valid: {valid}, Invalid: {invalid}")

# Check cache status
list_cached_tickers()

# Preview specific data
preview_cached_data('0700.HK')
```

## ğŸ”„ Next Steps

This system currently provides data collection, pattern labeling, and feature extraction. Future development includes:

1. **ğŸ¤– Model Training**: Train ML models on extracted features
2. **ğŸ” Pattern Detection**: Automated pattern recognition algorithms
3. **ğŸ“ˆ Backtesting**: Validate pattern performance over time
4. **âš¡ Real-time Analysis**: Live pattern detection and alerting
5. **ğŸ¯ Advanced Features**: Additional technical indicators and pattern types

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## ğŸ“„ License

This project is for personal use as part of a stock pattern recognition system.

## ğŸ™ Acknowledgments

- **Yahoo Finance**: Data source via `yfinance` library
- **Pandas**: Data manipulation and analysis
- **Jupyter**: Interactive development environment

---

**Ready to start collecting Hong Kong stock data for pattern recognition! ğŸš€** 