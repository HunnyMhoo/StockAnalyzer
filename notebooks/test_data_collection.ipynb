{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [1]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": 0.007947,
     "end_time": "2025-06-24T07:04:50.867640",
     "exception": true,
     "start_time": "2025-06-24T07:04:50.859693",
     "status": "failed"
    }
   },
   "outputs": [],
   "source": [
    "# Hong Kong Stock Data Collection\n",
    "\n",
    "This notebook demonstrates how to fetch and cache daily OHLCV data for Hong Kong stocks using Yahoo Finance. The data will be used for chart pattern recognition and model training.\n",
    "\n",
    "## Features\n",
    "- ‚úÖ Fetch data from Yahoo Finance\n",
    "- ‚úÖ Intelligent local caching\n",
    "- ‚úÖ Incremental updates\n",
    "- ‚úÖ Progress tracking\n",
    "- ‚úÖ Error handling and recovery\n",
    "- ‚úÖ Data validation and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and our data fetching module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "# Add the src directory to Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "# Import our data fetching functions\n",
    "from data_fetcher import (\n",
    "    fetch_hk_stocks,\n",
    "    validate_tickers,\n",
    "    preview_cached_data,\n",
    "    list_cached_tickers\n",
    ")\n",
    "\n",
    "# Standard data science libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìÖ Current date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "## Step 1: Define Target Stocks\n",
    "\n",
    "Let's define some popular Hong Kong stocks to fetch data for. These are commonly traded stocks that should have good data availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "# Define target Hong Kong stocks\n",
    "target_tickers = [\n",
    "    '6969.HK',  \n",
    "]\n",
    "\n",
    "# Validate ticker formats\n",
    "valid_tickers, invalid_tickers = validate_tickers(target_tickers)\n",
    "\n",
    "print(f\"üìä Target stocks: {len(target_tickers)} total\")\n",
    "print(f\"‚úÖ Valid tickers: {len(valid_tickers)} - {valid_tickers}\")\n",
    "if invalid_tickers:\n",
    "    print(f\"‚ùå Invalid tickers: {len(invalid_tickers)} - {invalid_tickers}\")\n",
    "\n",
    "# Display stock names for reference\n",
    "\n",
    "\n",
    "print(\"\\nüè¢ Stock names:\")\n",
    "for ticker in valid_tickers:\n",
    "    print(f\"  {ticker}: {stock_names.get(ticker, 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "valid_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "## Step 2: Set Date Range\n",
    "\n",
    "Define the date range for historical data. We'll fetch approximately 1 year of data for pattern recognition training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "# Define date range (1 year of data)\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"üìÖ Date range for data collection:\")\n",
    "print(f\"   Start: {start_date}\")\n",
    "print(f\"   End: {end_date}\")\n",
    "print(f\"   Duration: ~365 days\")\n",
    "\n",
    "# Calculate expected trading days (approximately 250 trading days per year)\n",
    "total_days = (datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days\n",
    "expected_trading_days = int(total_days * 5/7 * 0.95)  # Rough estimate excluding weekends and holidays\n",
    "\n",
    "print(f\"   Expected trading days: ~{expected_trading_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "## Step 3: Check Existing Cache\n",
    "\n",
    "Before fetching new data, let's see what's already cached locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "# Check existing cached data\n",
    "print(\"üìÅ Current cache status:\")\n",
    "list_cached_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "## Step 4: Fetch Stock Data\n",
    "\n",
    "Now let's fetch the data. This will use intelligent caching - if data already exists, it will only fetch missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "# Fetch stock data with caching\n",
    "print(\"üöÄ Starting data collection...\\n\")\n",
    "\n",
    "stock_data = fetch_hk_stocks(\n",
    "    tickers=valid_tickers,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    force_refresh=True  # Set to True to ignore cache and fetch fresh data\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data collection completed!\")\n",
    "print(f\"üìä Successfully fetched data for {len(stock_data)} stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "## Step 5: Data Validation and Preview\n",
    "\n",
    "Let's validate the fetched data and get a preview of what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "lines_to_next_cell": 2,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    }
   },
   "outputs": [],
   "source": [
    "# Validate data structure and content\n",
    "print(\"üîç Data validation:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for ticker, data in stock_data.items():\n",
    "    print(f\"\\nüìà {ticker} ({stock_names.get(ticker, 'Unknown')})\")\n",
    "    print(f\"   üìÖ Date range: {data.index.min().date()} to {data.index.max().date()}\")\n",
    "    print(f\"   üìä Records: {len(data)}\")\n",
    "    print(f\"   üìã Columns: {list(data.columns)}\")\n",
    "    print(f\"   üí∞ Price range: ${data['Close'].min():.2f} - ${data['Close'].max():.2f}\")\n",
    "    print(f\"   üìä Average volume: {data['Volume'].mean():,.0f}\")\n",
    "    \n",
    "    # Check for missing data\n",
    "    missing_data = data.isnull().sum().sum()\n",
    "    if missing_data > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Missing data points: {missing_data}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No missing data\")\n",
    "    \n",
    "    # Display recent data sample\n",
    "    print(f\"   üìã Recent data:\")\n",
    "    print(data.tail(3).round(2))\n",
    "\n",
    "print(f\"\\nüìä Overall statistics:\")\n",
    "print(f\"   Total records: {sum(len(data) for data in stock_data.values()):,}\")\n",
    "print(f\"   Average records per stock: {sum(len(data) for data in stock_data.values()) / len(stock_data):.0f}\")\n",
    "print(f\"\\n‚úÖ Data validation completed!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-language_info,-toc,-latex_envs"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
