{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Hong Kong Stock Bulk Data Collection - Comprehensive Guide\n",
    "\n",
    "This notebook provides **efficient, production-ready approaches** for bulk fetching Hong Kong stock data.\n",
    "\n",
    "## 📋 **What You'll Master**\n",
    "\n",
    "| Level | Approach | Best For |\n",
    "|-------|----------|----------|\n",
    "| 🔰 **Beginner** | Curated Stock Lists | Learning & Testing (10-50 stocks) |\n",
    "| 📊 **Intermediate** | Sector-Based Fetching | Targeted Analysis (50-200 stocks) |\n",
    "| 🚀 **Advanced** | Full Universe Discovery | Comprehensive Research (500+ stocks) |\n",
    "| ⚡ **Enterprise** | Parallel Processing | Production Systems (1000+ stocks) |\n",
    "\n",
    "## 🎯 **Key Features**\n",
    "- **Smart Rate Limiting**: Respects API constraints\n",
    "- **Error Recovery**: Robust retry logic with exponential backoff\n",
    "- **Progress Tracking**: Real-time monitoring for large operations\n",
    "- **Data Management**: Systematic saving and organization\n",
    "- **Memory Efficient**: Batch processing to handle large datasets\n",
    "\n",
    "---\n",
    "**📝 Note**: Run the Setup section first, then choose your preferred approach.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔧 **Setup & Configuration**\n",
    "\n",
    "**Run this section first** - All subsequent cells depend on this setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup Python Path\n",
    "notebook_dir = Path().absolute()\n",
    "src_dir = notebook_dir.parent / 'src'\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "print(\"✅ Standard libraries loaded\")\n",
    "print(f\"📁 Source path: {src_dir}\")\n",
    "print(f\"📍 Working directory: {notebook_dir}\")\n",
    "\n",
    "# Verify setup\n",
    "if src_dir.exists():\n",
    "    print(\"🎯 Setup successful - ready to proceed!\")\n",
    "else:\n",
    "    print(\"⚠️ Source directory not found - check your notebook location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Import Custom Modules and Improved Utilities\n",
    "try:\n",
    "    # Core stock data modules\n",
    "    from hk_stock_universe import (\n",
    "        get_hk_stock_list_static,\n",
    "        get_hk_stocks_by_sector,\n",
    "        get_comprehensive_hk_stock_list,\n",
    "        MAJOR_HK_STOCKS\n",
    "    )\n",
    "    \n",
    "    from bulk_data_fetcher import (\n",
    "        fetch_hk_stocks_bulk,\n",
    "        fetch_all_major_hk_stocks,\n",
    "        fetch_hk_tech_stocks,\n",
    "        create_bulk_fetch_summary,\n",
    "        save_bulk_data\n",
    "    )\n",
    "    \n",
    "    # Import the improved utilities we created\n",
    "    from bulk_collection_improved import (\n",
    "        BulkCollectionConfig,\n",
    "        BulkCollector,\n",
    "        ResultsManager,\n",
    "        create_beginner_collector,\n",
    "        create_enterprise_collector,\n",
    "        quick_demo\n",
    "    )\n",
    "    \n",
    "    print(\"✅ All modules imported successfully!\")\n",
    "    print(\"🚀 Enhanced utilities loaded - ready for efficient bulk collection!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    print(\"   1. Ensure you're running from the notebooks/ directory\")\n",
    "    print(\"   2. Check that all source files exist in ../src/\")\n",
    "    print(\"   3. Verify Python path setup in previous cell\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Global Configuration - Centralized Settings\n",
    "config = BulkCollectionConfig()\n",
    "\n",
    "print(\"📋 **Global Configuration**\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"📅 Date Range: {config.start_date} → {config.end_date}\")\n",
    "print(f\"📊 Period: {config.default_period_days} days\")\n",
    "print(f\"⚡ Batch Sizes: {config.batch_sizes}\")\n",
    "print(f\"⏱️ Delays: {config.delays}\")\n",
    "print(f\"🔄 Max Retries: {config.max_retries}\")\n",
    "print(f\"🛡️ Parallel Workers: {config.max_workers}\")\n",
    "\n",
    "print(\"\\n🎯 **Configuration Ready!**\")\n",
    "print(\"Choose your approach below based on your needs.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "# 🎯 **Choose Your Approach**\n",
    "\n",
    "Select the section that matches your experience level and requirements:\n",
    "\n",
    "| 🔰 **Beginner** | 📊 **Intermediate** | 🚀 **Advanced** | ⚡ **Enterprise** |\n",
    "|-----------------|---------------------|------------------|-------------------|\n",
    "| 10-50 stocks | 50-200 stocks | 200-500 stocks | 500+ stocks |\n",
    "| Safe & Simple | Sector Analysis | Full Universe | Parallel Processing |\n",
    "| 2-5 minutes | 10-30 minutes | 30-120 minutes | 2+ hours |\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🔰 **Level 1: Beginner - Quick Start**\n",
    "\n",
    "**Perfect for**: Learning, testing, small analysis projects\n",
    "**Time Required**: 2-5 minutes\n",
    "**Stocks**: 10-50 stocks\n",
    "\n",
    "### Features:\n",
    "- ✅ Conservative rate limiting (safe for any API)\n",
    "- ✅ Small batch sizes (easy to manage)\n",
    "- ✅ Clear progress tracking\n",
    "- ✅ Automatic error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Beginner Approach: Quick & Safe Stock Universe Exploration\n",
    "print(\"🔰 **BEGINNER LEVEL: Stock Universe Overview**\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Explore available stock categories (no API calls)\n",
    "print(\"\\n📊 **Available HK Stock Sectors:**\")\n",
    "sector_summary = []\n",
    "for sector, stocks in MAJOR_HK_STOCKS.items():\n",
    "    sector_summary.append({\n",
    "        'Sector': sector.replace('_', ' ').title(),\n",
    "        'Count': len(stocks),\n",
    "        'Examples': ', '.join(stocks[:3])\n",
    "    })\n",
    "\n",
    "sector_df = pd.DataFrame(sector_summary)\n",
    "display(sector_df)\n",
    "\n",
    "# Get major stocks overview\n",
    "all_major_stocks = get_hk_stock_list_static()\n",
    "print(f\"\\n📈 **Total Major Stocks Available**: {len(all_major_stocks)}\")\n",
    "print(f\"🔍 **Sample Tickers**: {all_major_stocks[:10]}\")\n",
    "\n",
    "# Select specific sectors for analysis\n",
    "tech_stocks = get_hk_stocks_by_sector('tech_stocks')\n",
    "finance_stocks = get_hk_stocks_by_sector('finance')\n",
    "\n",
    "print(f\"\\n💡 **Sector Breakdown:**\")\n",
    "print(f\"   💻 Tech Sector: {len(tech_stocks)} stocks\")\n",
    "print(f\"   🏦 Finance Sector: {len(finance_stocks)} stocks\")\n",
    "print(f\"   📊 Total Unique: {len(set(tech_stocks + finance_stocks))} stocks\")\n",
    "\n",
    "print(\"\\n✅ **Stock Universe Exploration Complete!**\")\n",
    "print(\"📋 Ready to fetch data using the improved utilities below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Beginner Demo: Fetch Top 10 Stocks with Enhanced Utilities\n",
    "print(\"🚀 **BEGINNER DEMO: Fetching Top 10 HK Stocks**\")\n",
    "print(\"Using improved utilities for better experience!\")\n",
    "\n",
    "# Create beginner-optimized collector\n",
    "beginner_collector = create_beginner_collector()\n",
    "\n",
    "print(f\"\\n📋 **Beginner Configuration:**\")\n",
    "print(f\"   ⏱️ Delay: {beginner_collector.config.get_delay('normal')}s (conservative)\")\n",
    "print(f\"   📦 Batch Size: {beginner_collector.config.get_batch_size('medium')} stocks\")\n",
    "print(f\"   🔄 Max Retries: {beginner_collector.config.max_retries}\")\n",
    "\n",
    "# Select first 10 major stocks for demo\n",
    "demo_stocks = all_major_stocks[:10]\n",
    "print(f\"\\n🎯 **Target Stocks**: {demo_stocks}\")\n",
    "\n",
    "# Fetch data using improved collector\n",
    "print(f\"\\n🔄 **Starting Fetch Process...**\")\n",
    "results = beginner_collector.fetch_sequential(\n",
    "    stock_list=demo_stocks,\n",
    "    fetch_function=fetch_hk_stocks_bulk,\n",
    "    level='small'\n",
    ")\n",
    "\n",
    "# Display results using improved manager\n",
    "print(f\"\\n📊 **RESULTS SUMMARY**\")\n",
    "ResultsManager.display_summary(results['data'], \"Beginner Demo Results\")\n",
    "\n",
    "# Show performance statistics\n",
    "stats = results['statistics']\n",
    "print(f\"\\n⚡ **Performance Metrics:**\")\n",
    "print(f\"   ⏱️ Total Time: {stats['total_time']:.1f}s\")\n",
    "print(f\"   📈 Success Rate: {stats['success_rate']:.1%}\")\n",
    "print(f\"   🚀 Processing Rate: {stats['processing_rate']:.2f} stocks/sec\")\n",
    "print(f\"   ✅ Successful: {stats['successful']} stocks\")\n",
    "print(f\"   ❌ Failed: {stats['failed']} stocks\")\n",
    "\n",
    "# Store results for potential use in other cells\n",
    "beginner_results = results\n",
    "print(f\"\\n🎉 **Beginner Demo Complete!** Results stored in 'beginner_results'.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 📊 **Level 2: Intermediate - Sector Analysis**\n",
    "\n",
    "**Perfect for**: Targeted analysis, sector research, comparative studies\n",
    "**Time Required**: 10-30 minutes  \n",
    "**Stocks**: 50-200 stocks\n",
    "\n",
    "### Features:\n",
    "- ✅ Sector-specific data collection\n",
    "- ✅ Optimized batch processing\n",
    "- ✅ Comprehensive progress tracking\n",
    "- ✅ Advanced error recovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Intermediate: Sector-Focused Analysis\n",
    "print(\"📊 **INTERMEDIATE LEVEL: Sector-Based Collection**\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create standard collector for intermediate use\n",
    "intermediate_collector = BulkCollector(config)\n",
    "\n",
    "# Select sectors for analysis (you can modify this)\n",
    "selected_sectors = ['tech_stocks', 'finance']  # Modify as needed\n",
    "print(f\"🎯 **Selected Sectors**: {[s.replace('_', ' ').title() for s in selected_sectors]}\")\n",
    "\n",
    "# Collect data for each sector\n",
    "sector_results = {}\n",
    "total_stocks_processed = 0\n",
    "\n",
    "for sector in selected_sectors:\n",
    "    print(f\"\\n🔄 **Processing {sector.replace('_', ' ').title()} Sector**\")\n",
    "    \n",
    "    if sector == 'tech_stocks':\n",
    "        # Use specialized tech fetcher\n",
    "        print(\"   💻 Using specialized tech stock fetcher...\")\n",
    "        sector_data = fetch_hk_tech_stocks(\n",
    "            start_date=config.start_date,\n",
    "            end_date=config.end_date,\n",
    "            batch_size=config.get_batch_size('medium'),\n",
    "            delay_between_batches=config.get_delay('normal')\n",
    "        )\n",
    "        # Convert to our result format\n",
    "        sector_result = {\n",
    "            'data': sector_data,\n",
    "            'statistics': {\n",
    "                'successful': len(sector_data),\n",
    "                'failed': 0,\n",
    "                'total_time': 0,  # Would be calculated in real fetch\n",
    "                'success_rate': 1.0 if sector_data else 0.0\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        # Use generic bulk fetcher for other sectors\n",
    "        sector_stocks = get_hk_stocks_by_sector(sector)\n",
    "        print(f\"   📊 Fetching {len(sector_stocks)} stocks...\")\n",
    "        \n",
    "        sector_result = intermediate_collector.fetch_sequential(\n",
    "            stock_list=sector_stocks,\n",
    "            fetch_function=fetch_hk_stocks_bulk,\n",
    "            level='medium'\n",
    "        )\n",
    "    \n",
    "    sector_results[sector] = sector_result\n",
    "    stocks_fetched = len(sector_result['data'])\n",
    "    total_stocks_processed += stocks_fetched\n",
    "    \n",
    "    print(f\"   ✅ {sector.replace('_', ' ').title()}: {stocks_fetched} stocks fetched\")\n",
    "    \n",
    "    # Display sector summary\n",
    "    ResultsManager.display_summary(\n",
    "        sector_result['data'], \n",
    "        f\"{sector.replace('_', ' ').title()} Sector Results\"\n",
    "    )\n",
    "\n",
    "# Overall summary\n",
    "print(f\"\\n🎉 **INTERMEDIATE ANALYSIS COMPLETE**\")\n",
    "print(f\"📊 **Total Stocks Processed**: {total_stocks_processed}\")\n",
    "print(f\"🏢 **Sectors Analyzed**: {len(selected_sectors)}\")\n",
    "\n",
    "# Show comparative statistics\n",
    "print(f\"\\n📈 **Sector Comparison:**\")\n",
    "for sector, result in sector_results.items():\n",
    "    stats = result['statistics']\n",
    "    print(f\"   {sector.replace('_', ' ').title()}: {stats['successful']} stocks \"\n",
    "          f\"({stats['success_rate']:.1%} success rate)\")\n",
    "\n",
    "# Store results for potential use\n",
    "intermediate_results = sector_results\n",
    "print(f\"\\n💾 Results stored in 'intermediate_results' for further analysis.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 🚀 **Level 3: Advanced - Full Universe Discovery**\n",
    "\n",
    "**Perfect for**: Comprehensive research, market analysis, data science projects\n",
    "**Time Required**: 30-120 minutes\n",
    "**Stocks**: 200-500+ stocks\n",
    "\n",
    "### Features:\n",
    "- ✅ Complete HK stock universe discovery\n",
    "- ✅ Systematic sampling strategies\n",
    "- ✅ Checkpoint support for resume capability\n",
    "- ✅ Memory-efficient processing\n",
    "- ✅ Comprehensive error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Advanced: Full Universe Discovery and Analysis\n",
    "print(\"🚀 **ADVANCED LEVEL: Complete HK Universe Discovery**\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Discover complete HK stock universe\n",
    "print(\"🔍 **Discovering Complete HK Stock Universe...**\")\n",
    "print(\"⚠️ This may take a few minutes for validation...\")\n",
    "\n",
    "universe_config = {\n",
    "    'include_major': True,\n",
    "    'validate_tickers': True,\n",
    "    'max_tickers': 200  # Adjust: None for complete universe, 200 for demo\n",
    "}\n",
    "\n",
    "stock_universe = get_comprehensive_hk_stock_list(**universe_config)\n",
    "all_discovered_stocks = sorted(stock_universe['valid_stocks'])\n",
    "\n",
    "print(f\"\\n📊 **Universe Discovery Results:**\")\n",
    "print(f\"   ✅ Valid Stocks: {len(stock_universe['valid_stocks'])}\")\n",
    "print(f\"   ❌ Invalid Stocks: {len(stock_universe['invalid_stocks'])}\")\n",
    "print(f\"   📈 Range: {all_discovered_stocks[0]} → {all_discovered_stocks[-1]}\")\n",
    "\n",
    "# Resource estimation for full universe\n",
    "total_stocks = len(all_discovered_stocks)\n",
    "estimated_time_hours = total_stocks * 1.5 / 3600\n",
    "estimated_api_calls = total_stocks\n",
    "estimated_data_mb = total_stocks * 0.1\n",
    "\n",
    "print(f\"\\n⚖️ **Resource Requirements:**\")\n",
    "print(f\"   ⏱️ Estimated Time: {estimated_time_hours:.1f} hours\")\n",
    "print(f\"   🌐 API Calls: {estimated_api_calls:,}\")\n",
    "print(f\"   💾 Data Size: ~{estimated_data_mb:.1f} MB\")\n",
    "\n",
    "# Smart sampling for demonstration\n",
    "DEMO_SIZE = 50  # Adjust based on your needs\n",
    "if total_stocks > DEMO_SIZE:\n",
    "    print(f\"\\n📋 **Demo Mode**: Using systematic sample of {DEMO_SIZE} stocks\")\n",
    "    # Systematic sampling for variety\n",
    "    step = max(1, total_stocks // DEMO_SIZE)\n",
    "    demo_stocks = all_discovered_stocks[::step][:DEMO_SIZE]\n",
    "    print(f\"   📍 Sample: Every {step}th stock\")\n",
    "else:\n",
    "    demo_stocks = all_discovered_stocks\n",
    "    print(f\"\\n📋 **Complete Set**: Using all {total_stocks} discovered stocks\")\n",
    "\n",
    "print(f\"🎯 **Target for Advanced Demo**: {len(demo_stocks)} stocks\")\n",
    "print(f\"📊 **Sample Range**: {demo_stocks[0]} → {demo_stocks[-1]}\")\n",
    "\n",
    "# Store universe data for next cell\n",
    "advanced_stock_universe = demo_stocks\n",
    "print(f\"\\n✅ **Universe Discovery Complete!** Ready for advanced fetching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Advanced: Execute with Checkpointing Support\n",
    "print(\"🚧 **ADVANCED EXECUTION: Fetch with Checkpoint Support**\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create advanced collector\n",
    "advanced_collector = BulkCollector(config)\n",
    "\n",
    "# Safety check and user confirmation\n",
    "EXECUTE_ADVANCED = True  # Set to True to execute\n",
    "CHECKPOINT_DIR = \"data/advanced_checkpoints\"\n",
    "\n",
    "print(f\"⚙️ **Advanced Configuration:**\")\n",
    "print(f\"   📦 Batch Size: {config.get_batch_size('large')}\")\n",
    "print(f\"   ⏱️ Delay: {config.get_delay('conservative')}s\")\n",
    "print(f\"   💾 Checkpoint Dir: {CHECKPOINT_DIR}\")\n",
    "print(f\"   🎯 Target Stocks: {len(advanced_stock_universe)}\")\n",
    "\n",
    "if not EXECUTE_ADVANCED:\n",
    "    print(\"\\n🛡️ **Safety Mode**: Advanced execution disabled\")\n",
    "    print(\"💡 Set EXECUTE_ADVANCED = True to run comprehensive fetch\")\n",
    "    print(f\"📊 Ready to process {len(advanced_stock_universe)} stocks\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n🚀 **EXECUTING ADVANCED FETCH WITH CHECKPOINTS**\")\n",
    "    \n",
    "    # Option 1: Checkpoint-enabled fetch (recommended for large operations)\n",
    "    print(\"🔄 **Method: Checkpoint-Enabled Fetch**\")\n",
    "    print(\"💡 Can be interrupted and resumed at any time\")\n",
    "    \n",
    "    advanced_results = advanced_collector.fetch_with_checkpoints(\n",
    "        stock_list=advanced_stock_universe,\n",
    "        fetch_function=fetch_hk_stocks_bulk,\n",
    "        checkpoint_dir=CHECKPOINT_DIR,\n",
    "        checkpoint_every=25  # Save progress every 25 stocks\n",
    "    )\n",
    "    \n",
    "    # Display comprehensive results\n",
    "    if advanced_results['data']:\n",
    "        print(f\"\\n📊 **ADVANCED RESULTS SUMMARY**\")\n",
    "        ResultsManager.display_summary(\n",
    "            advanced_results['data'], \n",
    "            \"Advanced Universe Discovery Results\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n🎉 **Advanced Analysis Complete!**\")\n",
    "        print(f\"✅ Successfully fetched: {len(advanced_results['data'])} stocks\")\n",
    "        print(f\"❌ Failed: {len(advanced_results['failed'])} stocks\")\n",
    "        \n",
    "        # Save comprehensive dataset\n",
    "        print(f\"\\n💾 **Saving Advanced Dataset...**\")\n",
    "        try:\n",
    "            save_result = ResultsManager.save_with_metadata(\n",
    "                data_dict=advanced_results['data'],\n",
    "                metadata={\n",
    "                    'collection_type': 'advanced_universe',\n",
    "                    'total_stocks': len(advanced_stock_universe),\n",
    "                    'successful': len(advanced_results['data']),\n",
    "                    'failed': len(advanced_results['failed']),\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'config': config.__dict__\n",
    "                },\n",
    "                output_dir=\"data/advanced_universe\"\n",
    "            )\n",
    "            print(f\"✅ Dataset saved: {save_result['total_files']} files\")\n",
    "            print(f\"📄 Metadata: {save_result['metadata_file']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Save operation failed: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"❌ No data collected - check error logs\")\n",
    "\n",
    "# Store results\n",
    "if 'advanced_results' in locals():\n",
    "    print(f\"\\n💾 Results stored in 'advanced_results' variable\")\n",
    "else:\n",
    "    print(f\"\\n💡 Execute the cell with EXECUTE_ADVANCED = True to run the fetch\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ⚡ **Level 4: Enterprise - Parallel Processing**\n",
    "\n",
    "**Perfect for**: Production systems, time-critical analysis, large-scale operations\n",
    "**Time Required**: 2+ hours (depending on scale)\n",
    "**Stocks**: 500+ stocks\n",
    "\n",
    "### Features:\n",
    "- ✅ Safe parallel processing with rate limiting\n",
    "- ✅ Enterprise-grade error handling\n",
    "- ✅ Performance monitoring and optimization\n",
    "- ✅ Production deployment templates\n",
    "\n",
    "### ⚠️ **WARNING**: Use with extreme caution - can overwhelm APIs!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Enterprise: Parallel Processing Demo with Safety Controls\n",
    "print(\"⚡ **ENTERPRISE LEVEL: Parallel Processing with Safety**\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Enterprise configuration\n",
    "class EnterpriseConfig:\n",
    "    \"\"\"Enterprise-specific settings with safety controls\"\"\"\n",
    "    MAX_WORKERS = 2  # Conservative - increase after testing\n",
    "    WORKER_DELAY = 1.0  # Delay per worker request\n",
    "    ENABLE_PARALLEL = False  # Safety switch - must be explicitly enabled\n",
    "    DEMO_SIZE = 10  # Small demo for safety\n",
    "\n",
    "print(f\"🛡️ **Enterprise Safety Configuration:**\")\n",
    "print(f\"   ⚡ Max Workers: {EnterpriseConfig.MAX_WORKERS}\")\n",
    "print(f\"   ⏱️ Worker Delay: {EnterpriseConfig.WORKER_DELAY}s\")\n",
    "print(f\"   🔒 Parallel Enabled: {EnterpriseConfig.ENABLE_PARALLEL}\")\n",
    "print(f\"   📊 Demo Size: {EnterpriseConfig.DEMO_SIZE}\")\n",
    "\n",
    "# Create enterprise collector\n",
    "enterprise_collector = create_enterprise_collector()\n",
    "\n",
    "# Demo dataset for parallel processing\n",
    "if 'all_major_stocks' in locals():\n",
    "    demo_parallel_stocks = all_major_stocks[:EnterpriseConfig.DEMO_SIZE]\n",
    "else:\n",
    "    # Fallback demo stocks\n",
    "    demo_parallel_stocks = ['0700.HK', '0005.HK', '0941.HK', '1299.HK', '2318.HK']\n",
    "\n",
    "print(f\"\\n🎯 **Parallel Demo Target**: {demo_parallel_stocks}\")\n",
    "\n",
    "if EnterpriseConfig.ENABLE_PARALLEL:\n",
    "    print(f\"\\n⚡ **EXECUTING PARALLEL PROCESSING**\")\n",
    "    print(f\"🚨 WARNING: Using {EnterpriseConfig.MAX_WORKERS} workers with {EnterpriseConfig.WORKER_DELAY}s delays\")\n",
    "    \n",
    "    # Execute parallel processing\n",
    "    parallel_results = enterprise_collector.fetch_parallel(\n",
    "        stock_list=demo_parallel_stocks,\n",
    "        fetch_function=fetch_hk_stocks_bulk,\n",
    "        max_workers=EnterpriseConfig.MAX_WORKERS\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n📊 **PARALLEL PROCESSING RESULTS**\")\n",
    "    ResultsManager.display_summary(\n",
    "        parallel_results['data'],\n",
    "        \"Enterprise Parallel Processing Results\"\n",
    "    )\n",
    "    \n",
    "    # Performance analysis\n",
    "    stats = parallel_results['statistics']\n",
    "    print(f\"\\n⚡ **Performance Analysis:**\")\n",
    "    print(f\"   ⏱️ Total Time: {stats['total_time']:.1f}s\")\n",
    "    print(f\"   📈 Success Rate: {stats['success_rate']:.1%}\")\n",
    "    print(f\"   🚀 Processing Rate: {stats['processing_rate']:.2f} stocks/sec\")\n",
    "    print(f\"   👥 Workers Used: {parallel_results['metadata']['max_workers']}\")\n",
    "    \n",
    "    # Compare with sequential baseline\n",
    "    print(f\"\\n📊 **Sequential vs Parallel Comparison:**\")\n",
    "    print(f\"   Sequential (estimated): {len(demo_parallel_stocks) * EnterpriseConfig.WORKER_DELAY:.1f}s\")\n",
    "    print(f\"   Parallel (actual): {stats['total_time']:.1f}s\")\n",
    "    speedup = (len(demo_parallel_stocks) * EnterpriseConfig.WORKER_DELAY) / stats['total_time']\n",
    "    print(f\"   🚀 Speedup: {speedup:.1f}x faster\")\n",
    "    \n",
    "    enterprise_results = parallel_results\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n🛡️ **PARALLEL PROCESSING DISABLED FOR SAFETY**\")\n",
    "    print(f\"🔧 **To Enable Enterprise Parallel Processing:**\")\n",
    "    print(f\"   1. Set EnterpriseConfig.ENABLE_PARALLEL = True\")\n",
    "    print(f\"   2. Test with small datasets first (5-10 stocks)\")\n",
    "    print(f\"   3. Monitor API response times carefully\")\n",
    "    print(f\"   4. Gradually increase workers (2 → 4 → 8)\")\n",
    "    print(f\"   5. Implement comprehensive monitoring\")\n",
    "    print(f\"   6. Have fallback to sequential processing\")\n",
    "    \n",
    "    print(f\"\\n⚡ **Enterprise Infrastructure Ready:**\")\n",
    "    print(f\"   📊 Demo Stocks: {len(demo_parallel_stocks)}\")\n",
    "    print(f\"   🔧 Workers Available: {EnterpriseConfig.MAX_WORKERS}\")\n",
    "    estimated_time = len(demo_parallel_stocks) * EnterpriseConfig.WORKER_DELAY / EnterpriseConfig.MAX_WORKERS\n",
    "    print(f\"   ⏱️ Estimated Time: {estimated_time:.1f}s\")\n",
    "    print(f\"   💡 Ready for production deployment!\")\n",
    "\n",
    "print(f\"\\n✅ **Enterprise Level Complete**\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "## 📊 **Summary & Best Practices**\n",
    "\n",
    "### 🎯 **Quick Reference Guide**\n",
    "\n",
    "| Your Need | Level | Typical Time | Best Approach |\n",
    "|-----------|-------|--------------|---------------|\n",
    "| Learning & Testing | 🔰 Beginner | 2-5 min | `create_beginner_collector()` |\n",
    "| Sector Analysis | 📊 Intermediate | 10-30 min | `BulkCollector()` with sector lists |\n",
    "| Market Research | 🚀 Advanced | 30-120 min | `fetch_with_checkpoints()` |\n",
    "| Production System | ⚡ Enterprise | 2+ hours | `create_enterprise_collector()` |\n",
    "\n",
    "### 🛡️ **Critical Success Factors**\n",
    "1. **Start Small**: Always test with 5-10 stocks first\n",
    "2. **Rate Limiting**: Respect API constraints (1-2s delays minimum)  \n",
    "3. **Error Handling**: Implement retry logic and checkpointing\n",
    "4. **Monitoring**: Track success rates and performance metrics\n",
    "5. **Progressive Scaling**: Gradually increase batch sizes and workers\n",
    "\n",
    "### 📈 **Performance Optimization Tips**\n",
    "- Use checkpointing for operations > 100 stocks\n",
    "- Monitor memory usage for large datasets\n",
    "- Implement caching for frequently accessed data  \n",
    "- Use systematic sampling for universe discovery\n",
    "- Have fallback strategies for API failures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Final Summary and Next Steps\n",
    "print(\"🎉 **BULK DATA COLLECTION NOTEBOOK COMPLETE!**\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Collect all results if available\n",
    "all_results = {}\n",
    "result_summary = []\n",
    "\n",
    "# Check what results we have from each level\n",
    "if 'beginner_results' in locals():\n",
    "    all_results['beginner'] = beginner_results\n",
    "    result_summary.append({\n",
    "        'Level': '🔰 Beginner',\n",
    "        'Stocks': len(beginner_results['data']),\n",
    "        'Success_Rate': f\"{beginner_results['statistics']['success_rate']:.1%}\",\n",
    "        'Time': f\"{beginner_results['statistics']['total_time']:.1f}s\"\n",
    "    })\n",
    "\n",
    "if 'intermediate_results' in locals():\n",
    "    total_intermediate = sum(len(r['data']) for r in intermediate_results.values())\n",
    "    all_results['intermediate'] = intermediate_results\n",
    "    result_summary.append({\n",
    "        'Level': '📊 Intermediate',\n",
    "        'Stocks': total_intermediate,\n",
    "        'Success_Rate': 'Varies by sector',\n",
    "        'Time': 'Varies by sector'\n",
    "    })\n",
    "\n",
    "if 'advanced_results' in locals():\n",
    "    all_results['advanced'] = advanced_results\n",
    "    result_summary.append({\n",
    "        'Level': '🚀 Advanced',\n",
    "        'Stocks': len(advanced_results['data']) if 'data' in advanced_results else 0,\n",
    "        'Success_Rate': 'Checkpointed',\n",
    "        'Time': 'Variable'\n",
    "    })\n",
    "\n",
    "if 'enterprise_results' in locals():\n",
    "    all_results['enterprise'] = enterprise_results\n",
    "    result_summary.append({\n",
    "        'Level': '⚡ Enterprise',\n",
    "        'Stocks': len(enterprise_results['data']),\n",
    "        'Success_Rate': f\"{enterprise_results['statistics']['success_rate']:.1%}\",\n",
    "        'Time': f\"{enterprise_results['statistics']['total_time']:.1f}s\"\n",
    "    })\n",
    "\n",
    "# Display session summary\n",
    "if result_summary:\n",
    "    print(f\"\\n📊 **SESSION RESULTS SUMMARY**\")\n",
    "    summary_df = pd.DataFrame(result_summary)\n",
    "    display(summary_df)\n",
    "    \n",
    "    total_stocks = sum(int(str(row['Stocks']).split()[0]) if isinstance(row['Stocks'], str) else row['Stocks'] \n",
    "                      for row in result_summary)\n",
    "    print(f\"\\n🎯 **Total Stocks Processed This Session**: {total_stocks}\")\n",
    "else:\n",
    "    print(f\"\\n💡 **No results collected** - Run the level sections above to see data collection in action!\")\n",
    "\n",
    "print(f\"\\n🚀 **WHAT YOU'VE ACCOMPLISHED:**\")\n",
    "print(f\"✅ Learned 4 different approaches to bulk data collection\")\n",
    "print(f\"✅ Used production-ready utilities with error handling\")\n",
    "print(f\"✅ Experienced progressive complexity (Beginner → Enterprise)\")\n",
    "print(f\"✅ Gained tools for any scale of HK stock analysis\")\n",
    "\n",
    "print(f\"\\n📋 **NEXT STEPS:**\")\n",
    "print(f\"1. 🔧 **Customize**: Modify configurations for your specific needs\")\n",
    "print(f\"2. 📊 **Scale**: Apply to your target stock universe size\")\n",
    "print(f\"3. 🏭 **Deploy**: Use enterprise features for production systems\")\n",
    "print(f\"4. 📈 **Analyze**: Process your collected data with feature extraction\")\n",
    "print(f\"5. 🔄 **Iterate**: Refine and optimize based on your results\")\n",
    "\n",
    "print(f\"\\n💡 **AVAILABLE UTILITIES:**\")\n",
    "print(f\"   📦 BulkCollectionConfig - Centralized configuration\")\n",
    "print(f\"   🔧 BulkCollector - Main collection engine\")  \n",
    "print(f\"   📊 ResultsManager - Data display and saving\")\n",
    "print(f\"   🔰 create_beginner_collector() - Safe defaults\")\n",
    "print(f\"   ⚡ create_enterprise_collector() - High performance\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"✅ **SUCCESS!** You're now equipped for professional-grade HK stock data collection! 🇭🇰📈\")\n",
    "\n",
    "# Save all configuration for reference\n",
    "final_config = {\n",
    "    'session_timestamp': datetime.now().isoformat(),\n",
    "    'levels_completed': list(all_results.keys()),\n",
    "    'total_stocks_processed': total_stocks if 'total_stocks' in locals() else 0,\n",
    "    'configuration_used': config.__dict__\n",
    "}\n",
    "\n",
    "print(f\"\\n💾 Session summary available in 'final_config' variable\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-language_info,-toc,-latex_envs"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
