{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Feature Extraction from Labeled Stock Patterns\n",
    "\n",
    "This notebook demonstrates how to extract numerical features from labeled stock patterns using the FeatureExtractor class. These features can then be used for machine learning model training.\n",
    "\n",
    "## User Story 1.3 Implementation\n",
    "- Extract 18+ numerical features from labeled patterns\n",
    "- Generate features across 4 categories: Trend Context, Correction Phase, False Support Break, Technical Indicators\n",
    "- Save results to CSV for ML training\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.feature_extractor import FeatureExtractor, extract_features_from_labels\n",
    "from src.pattern_labeler import PatternLabel, load_labeled_patterns\n",
    "from src.data_fetcher import fetch_hk_stocks, list_cached_tickers\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìÖ Notebook run time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Check Available Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check what labeled patterns we have\n",
    "labels_file = \"../labels/labeled_patterns.json\"\n",
    "notebook_labels_file = \"labels/labeled_patterns.json\"\n",
    "\n",
    "# Try both locations\n",
    "if os.path.exists(labels_file):\n",
    "    patterns_file = labels_file\n",
    "elif os.path.exists(notebook_labels_file):\n",
    "    patterns_file = notebook_labels_file\n",
    "else:\n",
    "    patterns_file = None\n",
    "\n",
    "if patterns_file:\n",
    "    try:\n",
    "        labeled_patterns = load_labeled_patterns(patterns_file)\n",
    "        print(f\"üìã Found {len(labeled_patterns)} labeled patterns:\")\n",
    "        \n",
    "        for i, pattern in enumerate(labeled_patterns[:5], 1):  # Show first 5\n",
    "            print(f\"  {i}. {pattern.ticker}: {pattern.start_date} to {pattern.end_date} ({pattern.label_type})\")\n",
    "        \n",
    "        if len(labeled_patterns) > 5:\n",
    "            print(f\"  ... and {len(labeled_patterns) - 5} more patterns\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading patterns: {e}\")\n",
    "        labeled_patterns = []\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No labeled patterns file found\")\n",
    "    labeled_patterns = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Method 1: Extract Features from Labeled Patterns File\n",
    "\n",
    "This is the main use case - extracting features from all labeled patterns at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if patterns_file and os.path.exists(patterns_file):\n",
    "    print(\"üîÑ Extracting features from labeled patterns...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract features from all labeled patterns\n",
    "        features_df = extract_features_from_labels(\n",
    "            labels_file=patterns_file,\n",
    "            output_file=\"../features/notebook_extracted_features.csv\"\n",
    "        )\n",
    "        \n",
    "        if not features_df.empty:\n",
    "            print(f\"‚úÖ Successfully extracted features!\")\n",
    "            print(f\"üìä Shape: {features_df.shape}\")\n",
    "            print(f\"üéØ Patterns processed: {len(features_df)}\")\n",
    "            \n",
    "            # Display the dataframe\n",
    "            display(features_df.head())\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No features extracted - check data availability\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting features: {e}\")\n",
    "        features_df = pd.DataFrame()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping - no labeled patterns file available\")\n",
    "    features_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Feature Analysis and Summary\n",
    "\n",
    "Analyze the extracted features and show statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Optional: Refresh Data Cache\n",
    "\n",
    "If you're experiencing data issues, you can refresh the cached data for your tickers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Refresh data cache for your tickers (only run if needed)\n",
    "tickers = ['0700.HK', '0005.HK', '0001.HK', '0388.HK', '0003.HK']\n",
    "\n",
    "# Calculate date range for 2 years of data\n",
    "from datetime import datetime, timedelta\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d')  # 2 years\n",
    "\n",
    "print(f\"üìÖ Refreshing data from {start_date} to {end_date}\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"üîÑ Refreshing {ticker}...\")\n",
    "    try:\n",
    "        data = fetch_hk_stocks([ticker], start_date, end_date, force_refresh=True)\n",
    "        if ticker in data:\n",
    "            print(f\"‚úÖ {ticker}: {len(data[ticker])} records\")\n",
    "        else:\n",
    "            print(f\"‚ùå {ticker}: Failed to fetch\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {ticker}: Error - {e}\")\n",
    "\n",
    "print(\"üéâ Data refresh completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if not features_df.empty:\n",
    "    # Analyze the extracted features\n",
    "    print(\"üìà Feature Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Separate metadata and feature columns\n",
    "    metadata_cols = ['ticker', 'start_date', 'end_date', 'label_type', 'notes']\n",
    "    feature_cols = [col for col in features_df.columns if col not in metadata_cols]\n",
    "    \n",
    "    print(f\"üìä Total columns: {len(features_df.columns)}\")\n",
    "    print(f\"üìã Metadata columns: {len(metadata_cols)}\")\n",
    "    print(f\"üî¢ Feature columns: {len(feature_cols)}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Feature Categories:\")\n",
    "    \n",
    "    # Categorize features\n",
    "    trend_features = [col for col in feature_cols if any(keyword in col for keyword in ['trend', 'sma', 'angle'])]\n",
    "    correction_features = [col for col in feature_cols if any(keyword in col for keyword in ['drawdown', 'recovery', 'down_day'])]\n",
    "    support_features = [col for col in feature_cols if any(keyword in col for keyword in ['support', 'break'])]\n",
    "    technical_features = [col for col in feature_cols if col in ['rsi_14', 'macd_diff', 'volatility', 'volume_avg_ratio']]\n",
    "    \n",
    "    print(f\"  üî∫ Trend Context: {len(trend_features)} features\")\n",
    "    print(f\"  üìâ Correction Phase: {len(correction_features)} features\")\n",
    "    print(f\"  üõ°Ô∏è  Support Break: {len(support_features)} features\")\n",
    "    print(f\"  üìä Technical Indicators: {len(technical_features)} features\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Total numerical features: {len(feature_cols)} (minimum required: 10)\")\n",
    "    \n",
    "    # Feature statistics\n",
    "    print(f\"\\nüìä Feature Statistics:\")\n",
    "    display(features_df[feature_cols].describe().round(4))\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_counts = features_df[feature_cols].isnull().sum()\n",
    "    if missing_counts.sum() > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing values detected:\")\n",
    "        for col, count in missing_counts[missing_counts > 0].items():\n",
    "            print(f\"  ‚Ä¢ {col}: {count} missing ({count/len(features_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No missing values in feature columns\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No features available to analyze\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Review what was accomplished and suggest next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"üéâ Feature Extraction Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check what files were created\n",
    "output_files = []\n",
    "features_dir = \"../features\"\n",
    "\n",
    "if os.path.exists(features_dir):\n",
    "    for file in os.listdir(features_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(features_dir, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            output_files.append((file, file_size))\n",
    "\n",
    "if output_files:\n",
    "    print(f\"üìÅ Generated files in {features_dir}/:\")\n",
    "    for file, size in output_files:\n",
    "        print(f\"  ‚Ä¢ {file} ({size:,} bytes)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No output files found\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature extraction completed successfully!\")\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"  1. Review the generated CSV files for data quality\")\n",
    "print(f\"  2. Use the features for machine learning model training\")\n",
    "print(f\"  3. Add more labeled patterns to increase dataset size\")\n",
    "print(f\"  4. Experiment with different FeatureExtractor parameters\")\n",
    "print(f\"  5. Consider feature engineering and selection techniques\")\n",
    "\n",
    "print(f\"\\nüìä Feature Categories Implemented:\")\n",
    "print(f\"  üî∫ Trend Context: prior_trend_return, above_sma_50_ratio, trend_angle\")\n",
    "print(f\"  üìâ Correction Phase: drawdown_pct, recovery_return_pct, down_day_ratio\")\n",
    "print(f\"  üõ°Ô∏è  False Support Break: support_level, support_break_depth_pct, false_break_flag, recovery_days, recovery_volume_ratio\")\n",
    "print(f\"  üìä Technical Indicators: sma_5/10/20, rsi_14, macd_diff, volatility, volume_avg_ratio\")\n",
    "\n",
    "print(f\"\\nüéØ User Story 1.3 Status: ‚úÖ COMPLETED\")\n",
    "print(f\"  ‚Ä¢ Minimum 10 features required: ‚úÖ (18+ implemented)\")\n",
    "print(f\"  ‚Ä¢ Configurable window size: ‚úÖ\")\n",
    "print(f\"  ‚Ä¢ CSV output format: ‚úÖ\")\n",
    "print(f\"  ‚Ä¢ Error handling and validation: ‚úÖ\")\n",
    "print(f\"  ‚Ä¢ Batch processing capability: ‚úÖ\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
