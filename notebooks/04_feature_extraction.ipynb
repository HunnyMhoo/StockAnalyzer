{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Feature Extraction from Labeled Stock Patterns\n",
    "\n",
    "This notebook demonstrates how to extract numerical features from labeled stock patterns using the FeatureExtractor class. These features can then be used for machine learning model training.\n",
    "\n",
    "## User Story 1.3 Implementation\n",
    "- Extract 18+ numerical features from labeled patterns\n",
    "- Generate features across 4 categories: Trend Context, Correction Phase, False Support Break, Technical Indicators\n",
    "- Save results to CSV for ML training\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.feature_extractor import FeatureExtractor, extract_features_from_labels\n",
    "from src.pattern_labeler import PatternLabel, load_labeled_patterns\n",
    "from src.data_fetcher import fetch_hk_stocks, list_cached_tickers\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n",
    "print(f\"ğŸ“… Notebook run time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Check Available Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Check what labeled patterns we have\n",
    "labels_file = \"../labels/labeled_patterns.json\"\n",
    "notebook_labels_file = \"labels/labeled_patterns.json\"\n",
    "\n",
    "# Try both locations\n",
    "if os.path.exists(labels_file):\n",
    "    patterns_file = labels_file\n",
    "elif os.path.exists(notebook_labels_file):\n",
    "    patterns_file = notebook_labels_file\n",
    "else:\n",
    "    patterns_file = None\n",
    "\n",
    "if patterns_file:\n",
    "    try:\n",
    "        labeled_patterns = load_labeled_patterns(patterns_file)\n",
    "        print(f\"ğŸ“‹ Found {len(labeled_patterns)} labeled patterns:\")\n",
    "        \n",
    "        for i, pattern in enumerate(labeled_patterns[:5], 1):  # Show first 5\n",
    "            print(f\"  {i}. {pattern.ticker}: {pattern.start_date} to {pattern.end_date} ({pattern.label_type})\")\n",
    "        \n",
    "        if len(labeled_patterns) > 5:\n",
    "            print(f\"  ... and {len(labeled_patterns) - 5} more patterns\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading patterns: {e}\")\n",
    "        labeled_patterns = []\n",
    "else:\n",
    "    print(\"âš ï¸  No labeled patterns file found\")\n",
    "    labeled_patterns = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Method 1: Extract Features from Labeled Patterns File\n",
    "\n",
    "This is the main use case - extracting features from all labeled patterns at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if patterns_file and os.path.exists(patterns_file):\n",
    "    print(\"ğŸ”„ Extracting features from labeled patterns...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract features from all labeled patterns\n",
    "        features_df = extract_features_from_labels(\n",
    "            labels_file=patterns_file,\n",
    "            output_file=\"../features/notebook_extracted_features.csv\"\n",
    "        )\n",
    "        \n",
    "        if not features_df.empty:\n",
    "            print(f\"âœ… Successfully extracted features!\")\n",
    "            print(f\"ğŸ“Š Shape: {features_df.shape}\")\n",
    "            print(f\"ğŸ¯ Patterns processed: {len(features_df)}\")\n",
    "            \n",
    "            # Display the dataframe\n",
    "            display(features_df.head())\n",
    "            \n",
    "        else:\n",
    "            print(\"âš ï¸  No features extracted - check data availability\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error extracting features: {e}\")\n",
    "        features_df = pd.DataFrame()\n",
    "else:\n",
    "    print(\"âš ï¸  Skipping - no labeled patterns file available\")\n",
    "    features_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Feature Analysis and Summary\n",
    "\n",
    "Analyze the extracted features and show statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Optional: Refresh Data Cache\n",
    "\n",
    "If you're experiencing data issues, you can refresh the cached data for your tickers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Refresh data cache for your tickers (only run if needed)\n",
    "tickers = ['0700.HK', '0005.HK', '0001.HK', '0388.HK', '0003.HK']\n",
    "\n",
    "# Calculate date range for 2 years of data\n",
    "from datetime import datetime, timedelta\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d')  # 2 years\n",
    "\n",
    "print(f\"ğŸ“… Refreshing data from {start_date} to {end_date}\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"ğŸ”„ Refreshing {ticker}...\")\n",
    "    try:\n",
    "        data = fetch_hk_stocks([ticker], start_date, end_date, force_refresh=True)\n",
    "        if ticker in data:\n",
    "            print(f\"âœ… {ticker}: {len(data[ticker])} records\")\n",
    "        else:\n",
    "            print(f\"âŒ {ticker}: Failed to fetch\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {ticker}: Error - {e}\")\n",
    "\n",
    "print(\"ğŸ‰ Data refresh completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if not features_df.empty:\n",
    "    # Analyze the extracted features\n",
    "    print(\"ğŸ“ˆ Feature Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Separate metadata and feature columns\n",
    "    metadata_cols = ['ticker', 'start_date', 'end_date', 'label_type', 'notes']\n",
    "    feature_cols = [col for col in features_df.columns if col not in metadata_cols]\n",
    "    \n",
    "    print(f\"ğŸ“Š Total columns: {len(features_df.columns)}\")\n",
    "    print(f\"ğŸ“‹ Metadata columns: {len(metadata_cols)}\")\n",
    "    print(f\"ğŸ”¢ Feature columns: {len(feature_cols)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Feature Categories:\")\n",
    "    \n",
    "    # Categorize features\n",
    "    trend_features = [col for col in feature_cols if any(keyword in col for keyword in ['trend', 'sma', 'angle'])]\n",
    "    correction_features = [col for col in feature_cols if any(keyword in col for keyword in ['drawdown', 'recovery', 'down_day'])]\n",
    "    support_features = [col for col in feature_cols if any(keyword in col for keyword in ['support', 'break'])]\n",
    "    technical_features = [col for col in feature_cols if col in ['rsi_14', 'macd_diff', 'volatility', 'volume_avg_ratio']]\n",
    "    \n",
    "    print(f\"  ğŸ”º Trend Context: {len(trend_features)} features\")\n",
    "    print(f\"  ğŸ“‰ Correction Phase: {len(correction_features)} features\")\n",
    "    print(f\"  ğŸ›¡ï¸  Support Break: {len(support_features)} features\")\n",
    "    print(f\"  ğŸ“Š Technical Indicators: {len(technical_features)} features\")\n",
    "    \n",
    "    print(f\"\\nâœ… Total numerical features: {len(feature_cols)} (minimum required: 10)\")\n",
    "    \n",
    "    # Feature statistics\n",
    "    print(f\"\\nğŸ“Š Feature Statistics:\")\n",
    "    display(features_df[feature_cols].describe().round(4))\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_counts = features_df[feature_cols].isnull().sum()\n",
    "    if missing_counts.sum() > 0:\n",
    "        print(f\"\\nâš ï¸  Missing values detected:\")\n",
    "        for col, count in missing_counts[missing_counts > 0].items():\n",
    "            print(f\"  â€¢ {col}: {count} missing ({count/len(features_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… No missing values in feature columns\")\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸  No features available to analyze\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Review what was accomplished and suggest next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ Feature Extraction Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check what files were created\n",
    "output_files = []\n",
    "features_dir = \"../features\"\n",
    "\n",
    "if os.path.exists(features_dir):\n",
    "    for file in os.listdir(features_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(features_dir, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            output_files.append((file, file_size))\n",
    "\n",
    "if output_files:\n",
    "    print(f\"ğŸ“ Generated files in {features_dir}/:\")\n",
    "    for file, size in output_files:\n",
    "        print(f\"  â€¢ {file} ({size:,} bytes)\")\n",
    "else:\n",
    "    print(\"âš ï¸  No output files found\")\n",
    "\n",
    "print(f\"\\nâœ… Feature extraction completed successfully!\")\n",
    "print(f\"\\nğŸš€ Next Steps:\")\n",
    "print(f\"  1. Review the generated CSV files for data quality\")\n",
    "print(f\"  2. Use the features for machine learning model training\")\n",
    "print(f\"  3. Add more labeled patterns to increase dataset size\")\n",
    "print(f\"  4. Experiment with different FeatureExtractor parameters\")\n",
    "print(f\"  5. Consider feature engineering and selection techniques\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Feature Categories Implemented:\")\n",
    "print(f\"  ğŸ”º Trend Context: prior_trend_return, above_sma_50_ratio, trend_angle\")\n",
    "print(f\"  ğŸ“‰ Correction Phase: drawdown_pct, recovery_return_pct, down_day_ratio\")\n",
    "print(f\"  ğŸ›¡ï¸  False Support Break: support_level, support_break_depth_pct, false_break_flag, recovery_days, recovery_volume_ratio\")\n",
    "print(f\"  ğŸ“Š Technical Indicators: sma_5/10/20, rsi_14, macd_diff, volatility, volume_avg_ratio\")\n",
    "\n",
    "print(f\"\\nğŸ¯ User Story 1.3 Status: âœ… COMPLETED\")\n",
    "print(f\"  â€¢ Minimum 10 features required: âœ… (18+ implemented)\")\n",
    "print(f\"  â€¢ Configurable window size: âœ…\")\n",
    "print(f\"  â€¢ CSV output format: âœ…\")\n",
    "print(f\"  â€¢ Error handling and validation: âœ…\")\n",
    "print(f\"  â€¢ Batch processing capability: âœ…\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
