{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üî∞ Basic Hong Kong Stock Data Collection\n",
    "\n",
    "**Perfect for:** Beginners, small-scale analysis, testing (10-50 stocks)\n",
    "\n",
    "This notebook provides a **simple, reliable approach** for collecting Hong Kong stock data in batches.\n",
    "\n",
    "## ‚úÖ What You'll Learn\n",
    "- Fetch 10-50 stocks safely with built-in rate limiting\n",
    "- Sector-based stock selection (Tech, Finance, Property)\n",
    "- Progress tracking and error handling\n",
    "- Data validation and quality checks\n",
    "- Safe caching and incremental updates\n",
    "\n",
    "## ‚è±Ô∏è Time Required\n",
    "- **Setup**: 2 minutes\n",
    "- **Small batch (10 stocks)**: 3-5 minutes  \n",
    "- **Medium batch (25 stocks)**: 8-12 minutes\n",
    "- **Large batch (50 stocks)**: 15-20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup using shared utilities\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from common_setup import get_date_range, import_common_modules, setup_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Initialize notebook environment\n",
    "print(\"üî∞ Basic Data Collection Setup\")\n",
    "validation = setup_notebook()\n",
    "\n",
    "# Import data collection modules\n",
    "modules = import_common_modules()\n",
    "get_hk_stock_list_static = modules[\"get_hk_stock_list_static\"]\n",
    "\n",
    "# Import specific bulk collection functions\n",
    "from bulk_data_fetcher import (create_bulk_fetch_summary,\n",
    "                               fetch_all_major_hk_stocks, fetch_hk_stocks_bulk,\n",
    "                               save_bulk_data)\n",
    "from hk_stock_universe import MAJOR_HK_STOCKS, get_hk_stocks_by_sector\n",
    "\n",
    "print(\"‚úÖ Setup completed - Ready for basic bulk collection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## üìä Step 1: Explore Available Stock Categories\n",
    "\n",
    "Let's see what stock categories are available for collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore available stock sectors\n",
    "print(\"üìä **Available HK Stock Sectors:**\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sector_info = []\n",
    "for sector, stocks in MAJOR_HK_STOCKS.items():\n",
    "    sector_info.append(\n",
    "        {\n",
    "            \"Sector\": sector.replace(\"_\", \" \").title(),\n",
    "            \"Count\": len(stocks),\n",
    "            \"Examples\": \", \".join(stocks[:3]),\n",
    "        }\n",
    "    )\n",
    "    print(f\"üè¢ {sector.upper()}: {len(stocks)} stocks\")\n",
    "    print(f\"   Examples: {', '.join(stocks[:3])}\")\n",
    "\n",
    "# Get total available stocks\n",
    "all_stocks = get_hk_stock_list_static()\n",
    "print(f\"\\nüìà **Total Available Stocks:** {len(all_stocks)}\")\n",
    "print(f\"üéØ **Recommended for beginners:** Start with 10-25 stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 2: Configure Collection Parameters\n",
    "\n",
    "Set up your data collection preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Modify these settings as needed\n",
    "COLLECTION_CONFIG = {\n",
    "    \"date_range_days\": 365,  # 1 year of data\n",
    "    \"batch_size\": 5,  # Process 5 stocks at a time (safe for beginners)\n",
    "    \"delay_between_batches\": 2.0,  # 2 seconds between batches (conservative)\n",
    "    \"max_stocks\": 25,  # Limit for safety\n",
    "    \"sectors_to_include\": [\"tech_stocks\", \"finance\", \"property\"],  # Focus sectors\n",
    "    \"force_refresh\": False,  # Use cache when available\n",
    "}\n",
    "\n",
    "# Calculate date range\n",
    "start_date, end_date = get_date_range(COLLECTION_CONFIG[\"date_range_days\"])\n",
    "\n",
    "print(\"‚öôÔ∏è **Collection Configuration:**\")\n",
    "print(f\"üìÖ Date Range: {start_date} to {end_date}\")\n",
    "print(f\"üìä Max Stocks: {COLLECTION_CONFIG['max_stocks']}\")\n",
    "print(f\"üîÑ Batch Size: {COLLECTION_CONFIG['batch_size']}\")\n",
    "print(f\"‚è±Ô∏è Delay: {COLLECTION_CONFIG['delay_between_batches']}s\")\n",
    "print(f\"üéØ Target Sectors: {', '.join(COLLECTION_CONFIG['sectors_to_include'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## üéØ Step 3: Select Stocks for Collection\n",
    "\n",
    "Choose from different selection strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Top Major Stocks (Recommended for beginners)\n",
    "print(\"üéØ **Stock Selection Strategies:**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Get major stocks (most reliable)\n",
    "major_stocks = get_hk_stock_list_static()[: COLLECTION_CONFIG[\"max_stocks\"]]\n",
    "\n",
    "# Get sector-specific stocks\n",
    "tech_stocks = get_hk_stocks_by_sector(\"tech_stocks\")\n",
    "finance_stocks = get_hk_stocks_by_sector(\"finance\")\n",
    "property_stocks = get_hk_stocks_by_sector(\"property\")\n",
    "\n",
    "print(f\"üìà **Strategy 1 - Major Stocks:** {len(major_stocks)} stocks\")\n",
    "print(f\"   Examples: {', '.join(major_stocks[:5])}\")\n",
    "\n",
    "print(f\"\\nüíª **Strategy 2 - Tech Focus:** {len(tech_stocks)} stocks\")\n",
    "print(f\"   Examples: {', '.join(tech_stocks[:3])}\")\n",
    "\n",
    "print(f\"\\nüè¶ **Strategy 3 - Finance Focus:** {len(finance_stocks)} stocks\")\n",
    "print(f\"   Examples: {', '.join(finance_stocks[:3])}\")\n",
    "\n",
    "print(f\"\\nüè¢ **Strategy 4 - Property Focus:** {len(property_stocks)} stocks\")\n",
    "print(f\"   Examples: {', '.join(property_stocks[:3])}\")\n",
    "\n",
    "# Choose your strategy (modify as needed)\n",
    "SELECTED_STRATEGY = \"major_stocks\"  # Options: major_stocks, tech, finance, property\n",
    "\n",
    "if SELECTED_STRATEGY == \"major_stocks\":\n",
    "    target_stocks = major_stocks\n",
    "elif SELECTED_STRATEGY == \"tech\":\n",
    "    target_stocks = tech_stocks[: COLLECTION_CONFIG[\"max_stocks\"]]\n",
    "elif SELECTED_STRATEGY == \"finance\":\n",
    "    target_stocks = finance_stocks[: COLLECTION_CONFIG[\"max_stocks\"]]\n",
    "elif SELECTED_STRATEGY == \"property\":\n",
    "    target_stocks = property_stocks[: COLLECTION_CONFIG[\"max_stocks\"]]\n",
    "else:\n",
    "    target_stocks = major_stocks\n",
    "\n",
    "print(f\"\\n‚úÖ **Selected Strategy:** {SELECTED_STRATEGY}\")\n",
    "print(f\"üéØ **Target Stocks:** {len(target_stocks)} stocks\")\n",
    "print(f\"üìã **Stock List:** {', '.join(target_stocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Execute Data Collection\n",
    "\n",
    "Run the bulk data collection with progress tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute bulk data collection with smart logging\n",
    "print(\"üöÄ **Starting Basic Bulk Data Collection**\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Collecting {len(target_stocks)} stocks\")\n",
    "print(f\"üìÖ Date range: {start_date} to {end_date}\")\n",
    "print(\n",
    "    f\"‚è±Ô∏è Estimated time: {len(target_stocks) * COLLECTION_CONFIG['delay_between_batches'] / 60:.1f} minutes\"\n",
    ")\n",
    "\n",
    "# Configure logging level (set to False to reduce output)\n",
    "VERBOSE_LOGGING = False  # Set to True for detailed per-stock logging\n",
    "\n",
    "# Run the collection with progress tracking\n",
    "collected_data = {}\n",
    "failed_stocks = []\n",
    "start_time = time.time()  # Track collection time\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"\\nüîÑ Processing {len(target_stocks)} stocks in batches of {COLLECTION_CONFIG['batch_size']}...\"\n",
    "    )\n",
    "\n",
    "    # Process stocks with progress bar instead of individual logs\n",
    "    with tqdm(total=len(target_stocks), desc=\"Collecting data\", unit=\"stocks\") as pbar:\n",
    "        for i in range(0, len(target_stocks), COLLECTION_CONFIG[\"batch_size\"]):\n",
    "            batch = target_stocks[i : i + COLLECTION_CONFIG[\"batch_size\"]]\n",
    "\n",
    "            # Process batch quietly\n",
    "            try:\n",
    "                batch_data = fetch_hk_stocks_bulk(\n",
    "                    tickers=batch,\n",
    "                    start_date=start_date,\n",
    "                    end_date=end_date,\n",
    "                    batch_size=len(batch),\n",
    "                    delay_between_batches=COLLECTION_CONFIG[\"delay_between_batches\"],\n",
    "                    force_refresh=COLLECTION_CONFIG[\"force_refresh\"],\n",
    "                    verbose=VERBOSE_LOGGING,  # Control verbosity\n",
    "                )\n",
    "\n",
    "                # Merge successful results\n",
    "                collected_data.update(batch_data)\n",
    "\n",
    "                # Track failed stocks (quietly)\n",
    "                batch_failed = [stock for stock in batch if stock not in batch_data]\n",
    "                failed_stocks.extend(batch_failed)\n",
    "\n",
    "                # Update progress bar with summary\n",
    "                success_count = len(batch_data)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"Success\": f\"{len(collected_data)}/{len(target_stocks)}\",\n",
    "                        \"Batch\": f\"{success_count}/{len(batch)}\",\n",
    "                    }\n",
    "                )\n",
    "                pbar.update(len(batch))\n",
    "\n",
    "            except Exception as e:\n",
    "                if VERBOSE_LOGGING:\n",
    "                    print(f\"   ‚ö†Ô∏è Batch error: {e}\")\n",
    "                failed_stocks.extend(batch)\n",
    "                pbar.update(len(batch))\n",
    "                continue\n",
    "\n",
    "    # Print comprehensive summary\n",
    "    from common_setup import print_collection_summary\n",
    "\n",
    "    print_collection_summary(\n",
    "        collected_data=collected_data,\n",
    "        failed_stocks=failed_stocks,\n",
    "        target_count=len(target_stocks),\n",
    "        start_time=start_time,\n",
    "        show_failed_details=True,\n",
    "        max_failed_shown=5,  # Keep it brief for basic collection\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå **Collection Error:** {e}\")\n",
    "    collected_data = {}\n",
    "    failed_stocks = target_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## üìä Step 5: Data Quality Analysis\n",
    "\n",
    "Analyze the collected data quality and completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze collected data quality\n",
    "if collected_data:\n",
    "    print(\"üìä **Data Quality Analysis**\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Create summary\n",
    "    summary_df = create_bulk_fetch_summary(collected_data)\n",
    "\n",
    "    print(f\"üìà **Overall Statistics:**\")\n",
    "    print(f\"   Total stocks collected: {len(summary_df)}\")\n",
    "    print(f\"   Total records: {summary_df['Records'].sum():,}\")\n",
    "    print(f\"   Average records per stock: {summary_df['Records'].mean():.0f}\")\n",
    "    print(\n",
    "        f\"   Date range: {summary_df['Start Date'].min()} to {summary_df['End Date'].max()}\"\n",
    "    )\n",
    "\n",
    "    # Quality metrics\n",
    "    avg_completeness = summary_df[\"Records\"].mean()\n",
    "    min_records = summary_df[\"Records\"].min()\n",
    "    max_records = summary_df[\"Records\"].max()\n",
    "\n",
    "    print(f\"\\nüéØ **Quality Metrics:**\")\n",
    "    print(f\"   Minimum records: {min_records}\")\n",
    "    print(f\"   Maximum records: {max_records}\")\n",
    "    print(f\"   Completeness ratio: {min_records/max_records:.2%}\")\n",
    "\n",
    "    # Show detailed summary\n",
    "    print(f\"\\nüìã **Detailed Summary:**\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Check for potential issues\n",
    "    low_quality_stocks = summary_df[summary_df[\"Records\"] < avg_completeness * 0.8]\n",
    "    if not low_quality_stocks.empty:\n",
    "        print(f\"\\n‚ö†Ô∏è **Stocks with lower data quality:**\")\n",
    "        print(low_quality_stocks[[\"Ticker\", \"Records\"]].to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ **All stocks have good data quality!**\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data collected - check your configuration and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## üíæ Step 6: Save Collected Data\n",
    "\n",
    "Save the data with proper organization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save collected data\n",
    "if collected_data:\n",
    "    print(\"üíæ **Saving Collected Data**\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Save using the bulk data saver\n",
    "    try:\n",
    "        saved_files = save_bulk_data(\n",
    "            stock_data=collected_data,\n",
    "            base_filename=f\"basic_collection_{datetime.now().strftime('%Y%m%d')}\",\n",
    "        )\n",
    "\n",
    "        print(\"‚úÖ **Data saved successfully!**\")\n",
    "        print(f\"üìÅ **Files created:**\")\n",
    "        for file_path in saved_files:\n",
    "            file_size = len(str(file_path))  # Rough estimate\n",
    "            print(f\"   ‚Ä¢ {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå **Save Error:** {e}\")\n",
    "        print(\"Data is still available in memory as 'collected_data'\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## üìà Step 7: Quick Data Preview\n",
    "\n",
    "Preview some of the collected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview collected data\n",
    "if collected_data:\n",
    "    print(\"üìà **Data Preview**\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Show first stock as example\n",
    "    first_ticker = list(collected_data.keys())[0]\n",
    "    first_data = collected_data[first_ticker]\n",
    "\n",
    "    print(f\"üìä **Sample Data for {first_ticker}:**\")\n",
    "    print(f\"   Records: {len(first_data)}\")\n",
    "    print(f\"   Columns: {list(first_data.columns)}\")\n",
    "    print(\n",
    "        f\"   Date range: {first_data.index[0].date()} to {first_data.index[-1].date()}\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìã **Recent data sample:**\")\n",
    "    print(first_data.tail().round(2))\n",
    "\n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìä **Price Statistics for {first_ticker}:**\")\n",
    "    print(\n",
    "        f\"   Close price range: ${first_data['Close'].min():.2f} - ${first_data['Close'].max():.2f}\"\n",
    "    )\n",
    "    print(f\"   Average volume: {first_data['Volume'].mean():,.0f}\")\n",
    "    print(f\"   Volatility (std): {first_data['Close'].std():.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data available for preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## ‚úÖ Collection Summary & Next Steps\n",
    "\n",
    "Review what was accomplished and suggest next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéâ **Basic Data Collection Summary**\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if collected_data:\n",
    "    total_records = sum(len(data) for data in collected_data.values())\n",
    "\n",
    "    print(f\"‚úÖ **Success!** Collected data for {len(collected_data)} stocks\")\n",
    "    print(f\"üìä Total records: {total_records:,}\")\n",
    "    print(f\"üìÖ Date range: {start_date} to {end_date}\")\n",
    "    print(f\"‚è±Ô∏è Collection strategy: {SELECTED_STRATEGY}\")\n",
    "\n",
    "    print(f\"\\nüöÄ **Next Steps:**\")\n",
    "    print(f\"   1. Use '04_feature_extraction.ipynb' to extract technical indicators\")\n",
    "    print(f\"   2. Try '05_pattern_model_training.ipynb' for ML model training\")\n",
    "    print(f\"   3. Explore '07_pattern_match_visualization.ipynb' for charts\")\n",
    "    print(f\"   4. Scale up with '02_advanced_data_collection.ipynb'\")\n",
    "\n",
    "    print(f\"\\nüéØ **Tips for Next Time:**\")\n",
    "    print(f\"   ‚Ä¢ Increase max_stocks to 50-100 for more comprehensive analysis\")\n",
    "    print(f\"   ‚Ä¢ Try different sectors (tech_stocks, finance, property)\")\n",
    "    print(f\"   ‚Ä¢ Reduce delay_between_batches to 1.0s for faster collection\")\n",
    "    print(f\"   ‚Ä¢ Use force_refresh=True to get the latest data\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå **Collection failed - Troubleshooting:**\")\n",
    "    print(\"   1. Check internet connection\")\n",
    "    print(\"   2. Verify ticker symbols are valid (.HK format)\")\n",
    "    print(\"   3. Try reducing max_stocks to 10\")\n",
    "    print(\"   4. Increase delay_between_batches to 3.0s\")\n",
    "\n",
    "print(f\"\\nüìÖ **Collection completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---\n",
    "**üî∞ Basic Hong Kong Stock Data Collection**  \n",
    "*Simple, reliable bulk data collection for beginners - up to 50 stocks* "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all,-language_info,-toc,-latex_envs"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
